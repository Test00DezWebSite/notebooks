{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from backtester import matlab, backtester\n",
    "from backtester.analysis import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "\n",
    "import itertools\n",
    "\n",
    "from backtester.exoinfo import EXOInfo\n",
    "from exobuilder.data.exostorage import EXOStorage\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from pandas.tseries.offsets import *\n",
    "\n",
    "from sklearn import linear_model, svm, cross_validation, naive_bayes, ensemble, tree, neighbors, decomposition, preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.plotly as py  \n",
    "import plotly.tools as tls   \n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pprint\n",
    "%pylab inline\n",
    "figsize(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading global setting for MongoDB etc.\n",
    "from scripts.settings import *\n",
    "\n",
    "try:\n",
    "    from scripts.settings_local import *\n",
    "except:\n",
    "    pass\n",
    "\n",
    "storage = EXOStorage(MONGO_CONNSTR, MONGO_EXO_DB)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "exo_list = storage.exo_list()\n",
    "pp.pprint(exo_list)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for e in exo_list:\n",
    "    exo_series, exo_dict = storage.load_series(e)\n",
    "    \n",
    "    exo_series = exo_series[exo_series.columns[0]]\n",
    "    df[exo_dict['name']] = exo_series\n",
    "#exo_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#px_ser = df.ZS_PutSpread.dropna()\n",
    "px_ser = df.ZC_ContFut.dropna()\n",
    "px_ser.dropna().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exo_price = pd.Series(px_ser, name='exo')\n",
    "\n",
    "data = pd.DataFrame(data=exo_price.dropna())\n",
    "\n",
    "dataset_df = pd.DataFrame(data=exo_price)\n",
    "\n",
    "'''dataset_df['target'] = dataset_df.exo.diff().shift(-1)\n",
    "dataset_df['features_diff1'] = dataset_df.exo.diff()\n",
    "dataset_df['features_diff10'] = dataset_df.exo.diff(10)\n",
    "dataset_df['features_diff20'] = dataset_df.exo.diff(20)\n",
    "dataset_df['features_diff50'] = dataset_df.exo.diff(50)\n",
    "'''\n",
    "\n",
    "dataset_df['target'] = dataset_df.exo.shift(-1)\n",
    "#dataset_df['features_px'] = dataset_df.exo\n",
    "dataset_df['features_shift1'] = dataset_df.exo.shift(1)\n",
    "dataset_df['features_shift2'] = dataset_df.exo.shift(2)\n",
    "dataset_df['features_shift3'] = dataset_df.exo.shift(3)\n",
    "dataset_df['features_shift5'] = dataset_df.exo.shift(5)\n",
    "dataset_df['features_shift10'] = dataset_df.exo.shift(10)\n",
    "\n",
    "dataset_df['features_ma5'] = dataset_df.exo.rolling(5).mean()\n",
    "dataset_df['features_ma10'] = dataset_df.exo.rolling(10).mean()\n",
    "dataset_df['features_ma20'] = dataset_df.exo.rolling(20).mean()\n",
    "dataset_df['features_ma30'] = dataset_df.exo.rolling(30).mean()\n",
    "\n",
    "dataset_df['features_relstr5'] = dataset_df.exo - dataset_df.exo.rolling(5).mean()\n",
    "dataset_df['features_relstr10'] = dataset_df.exo - dataset_df.exo.rolling(10).mean()\n",
    "dataset_df['features_relstr20'] = dataset_df.exo - dataset_df.exo.rolling(20).mean()\n",
    "dataset_df['features_relstra30'] = dataset_df.exo - dataset_df.exo.rolling(30).mean()\n",
    "\n",
    "dataset_df.dropna(inplace=True)\n",
    "\n",
    "#dataset_df = pd.DataFrame(data=preprocessing.StandardScaler().fit_transform(dataset_df.values), \n",
    "#                          index=dataset_df.index, columns=dataset_df.columns)\n",
    "\n",
    "#dataset_df = pd.DataFrame(data=preprocessing.RobustScaler().fit_transform(dataset_df.values), \n",
    "#                          index=dataset_df.index, columns=dataset_df.columns)\n",
    "\n",
    "target = dataset_df.target\n",
    "features = dataset_df.filter(like='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(dataset_df, alpha=0.2, figsize=(6, 6), diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=dataset_df, kind=\"reg\", diag_kind=\"kde\", size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm.tsa.adfuller(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(target, lags=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = linear_model.LinearRegression()\n",
    "#model = neighbors.KNeighborsRegressor(5)\n",
    "#model = ensemble.AdaBoostRegressor(n_estimators=300, learning_rate=1)\n",
    "model = ensemble.RandomForestRegressor()\n",
    "\n",
    "model.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = features[pd.Series(model.feature_importances_, index=features.columns).sort_values()[-3:].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.predict(features)\n",
    "\n",
    "prediction_series = pd.Series(model.predict(features), name='Prediction', index=dataset_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([prediction_series, px_ser], axis=1).ix['2016'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Streaming\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#py.sign_in('tmqr', '8rctfyu197')\n",
    "py.sign_in('dmveden', 'rzbs7xw8ft')\n",
    "\n",
    "tls.set_credentials_file(username='dmveden', api_key='rzbs7xw8ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get stream id from stream id list \n",
    "stream_id1 = 'twfcm3v44s'\n",
    "stream_id2 = '5dnfr3e5d8'\n",
    "stream_id3 = '1ynb4ujpbt'\n",
    "stream_id4 = '8k95n9xp75'\n",
    "\n",
    "# Make instance of stream id object \n",
    "stream_1 = go.Stream(\n",
    "    token=stream_id1,  # link stream id to 'token' key\n",
    "    maxpoints=60      # keep a max of 80 pts on screen\n",
    ")\n",
    "\n",
    "# Make instance of stream id object \n",
    "stream_2 = go.Stream(\n",
    "    token=stream_id2,  # link stream id to 'token' key\n",
    "    maxpoints=60      # keep a max of 80 pts on screen\n",
    ")\n",
    "\n",
    "# Make instance of stream id object \n",
    "stream_3 = go.Stream(\n",
    "    token=stream_id3,  # link stream id to 'token' key\n",
    "    maxpoints=60      # keep a max of 80 pts on screen\n",
    ")\n",
    "\n",
    "# Make instance of stream id object \n",
    "stream_4 = go.Stream(\n",
    "    token=stream_id4,  # link stream id to 'token' key\n",
    "    maxpoints=60      # keep a max of 80 pts on screen\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trace1 = go.Scatter(x=[], y=[], stream=stream_1, name='EXO Price')\n",
    "trace2 = go.Scatter(x=[], y=[], stream=stream_2, name='Prediction Values', marker=dict(color='rgb(148, 103, 189)'))\n",
    "trace3 = go.Scatter(x=[], y=[], stream=stream_3, name='Model Target', marker=dict(color='rgb(0, 255, 0'))\n",
    "#trace4 = go.Scatter(x=[], y=[], stream=stream_4, name='Low Confidence Interval, 95%', marker=dict(color='rgb(255, 0, 0'))\n",
    "\n",
    "#data = go.Data([trace1, trace2, trace3, trace4])\n",
    "data = go.Data([trace1, trace2])\n",
    "#data = go.Data([trace2, trace3])\n",
    "\n",
    "# Add title to layout object\n",
    "layout = go.Layout(title='Machine Learning Regression Prediction, retrain on every bar')\n",
    "\n",
    "# Make a figure object\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Send fig to Plotly, initialize streaming plot, open new tab\n",
    "py.iplot(fig, filename='python-streaming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We will provide the stream link object the same token that's associated with the trace we wish to stream to\n",
    "s_1 = py.Stream(stream_id=stream_id1)\n",
    "s_2 = py.Stream(stream_id=stream_id2)\n",
    "s_3 = py.Stream(stream_id=stream_id3)\n",
    "#s_4 = py.Stream(stream_id=stream_id4)\n",
    "\n",
    "# We then open a connection\n",
    "s_1.open()\n",
    "s_2.open()\n",
    "s_3.open()\n",
    "#s_4.open()\n",
    "\n",
    "# (*) Import module keep track and format current time\n",
    "import datetime \n",
    "import time   \n",
    " \n",
    "i = 50  # a counter\n",
    "\n",
    "only_new_predictions_flag = True\n",
    "\n",
    "dataset_df = pd.DataFrame()\n",
    "prediction_series = pd.Series()\n",
    "\n",
    "while True:\n",
    "    if i >= px_ser.dropna().size:\n",
    "        break\n",
    "\n",
    "    '''dataset_df['target'] = px_ser.diff().shift(-1)\n",
    "    dataset_df['features_diff1'] = px_ser.diff()\n",
    "    dataset_df['features_diff10'] = px_ser.diff(10)\n",
    "    dataset_df['features_diff20'] = px_ser.diff(20)\n",
    "    dataset_df['features_diff50'] = px_ser.diff(50)\n",
    "    '''\n",
    "    dataset_df = pd.DataFrame(index=px_ser.dropna().iloc[:i].index)\n",
    "    \n",
    "    px_ser_slice = px_ser[dataset_df.index].iloc[:i]\n",
    "    \n",
    "    dataset_df['target'] = px_ser_slice.shift(-10)\n",
    "    \n",
    "    #dataset_df['features_px'] = px_ser\n",
    "    dataset_df['features_shift1'] = px_ser_slice.shift(1)\n",
    "    dataset_df['features_shift2'] = px_ser_slice.shift(2)\n",
    "    dataset_df['features_shift3'] = px_ser_slice.shift(3)\n",
    "    dataset_df['features_shift5'] = px_ser_slice.shift(5)\n",
    "    dataset_df['features_shift10'] = px_ser_slice.shift(10)\n",
    "\n",
    "    dataset_df['features_ma5'] = px_ser_slice.rolling(5).mean()\n",
    "    dataset_df['features_ma10'] = px_ser_slice.rolling(10).mean()\n",
    "    dataset_df['features_ma20'] = px_ser_slice.rolling(20).mean()\n",
    "    dataset_df['features_ma30'] = px_ser_slice.rolling(30).mean()\n",
    "\n",
    "    dataset_df['features_relstr5'] = px_ser_slice - px_ser_slice.rolling(5).mean()\n",
    "    dataset_df['features_relstr10'] = px_ser_slice - px_ser_slice.rolling(10).mean()\n",
    "    dataset_df['features_relstr20'] = px_ser_slice - px_ser_slice.rolling(20).mean()\n",
    "    dataset_df['features_relstra30'] = px_ser_slice - px_ser_slice.rolling(30).mean()\n",
    "    \n",
    "    predict_features = dataset_df.filter(like='features').dropna()\n",
    "    \n",
    "    dataset_df.dropna(inplace=True)\n",
    "\n",
    "    #dataset_df = pd.DataFrame(data=preprocessing.StandardScaler().fit_transform(dataset_df.values), \n",
    "    #                          index=dataset_df.index, columns=dataset_df.columns)\n",
    "\n",
    "    #dataset_df = pd.DataFrame(data=preprocessing.RobustScaler().fit_transform(dataset_df.values), \n",
    "    #                          index=dataset_df.index, columns=dataset_df.columns)\n",
    "\n",
    "    target = dataset_df.target\n",
    "\n",
    "    features = dataset_df.filter(like='features')\n",
    "    \n",
    "    #model = linear_model.LinearRegression()\n",
    "    #model = linear_model.ElasticNet()\n",
    "    #model = linear_model.RANSACRegressor()\n",
    "    \n",
    "    #knn = neighbors.KNeighborsRegressor(5)\n",
    "    #lr = linear_model.LinearRegression()\n",
    "    model = ensemble.BaggingRegressor(base_estimator=None, n_estimators=50)\n",
    "    \n",
    "    #model = linear_model.RANSACRegressor()\n",
    "    #model = tree.DecisionTreeRegressor(max_depth=4)\n",
    "    #model = svm.NuSVR()\n",
    "    #model = ensemble.AdaBoostRegressor(n_estimators=10)\n",
    "    #model = ensemble.GradientBoostingRegressor()\n",
    "    #model = ensemble.RandomForestRegressor(n_estimators=50, max_depth=5, n_jobs=-1)\n",
    "    #model = neighbors.KNeighborsRegressor(5, n_jobs=-1)\n",
    "    \n",
    "    model.fit(features.iloc[:i], target.iloc[:i])\n",
    "        \n",
    "    '''if i <= px_ser.size/4:\n",
    "        model = neighbors.KNeighborsRegressor(5, n_jobs=-1)\n",
    "        model.fit(features.iloc[:i], target.iloc[:i])\n",
    "        print('NO FITTING FROM',  px_ser[dataset_df.index].iloc[:i].index[-1])'''\n",
    "    \n",
    "    '''if prediction_series.size == 0:    \n",
    "        prediction_series = pd.Series(model.predict(predict_features.iloc[:i]), index=predict_features.iloc[:i].index, name='Prediction')\n",
    "    \n",
    "    else:\n",
    "        prediction_series = pd.concat([prediction_series,\n",
    "                                       pd.Series(model.predict(predict_features.iloc[:i])[-1], \n",
    "                                                 index=[predict_features.iloc[:i].index[-1] + pd.DateOffset(1)])])'''\n",
    "    \n",
    "        \n",
    "    prediction_series = pd.Series(model.predict(features.iloc[:i]), \n",
    "                                  index=features.iloc[:i].index, name='Prediction')    \n",
    "        \n",
    "    if only_new_predictions_flag == True:\n",
    "        x_1 = px_ser_slice.index\n",
    "        y_1 = px_ser_slice\n",
    "\n",
    "        x_2 = prediction_series.iloc[:i].index\n",
    "        y_2 = prediction_series.iloc[:i]\n",
    "   \n",
    "        x_3 = target.iloc[:i].index\n",
    "        y_3 = target.iloc[:i]\n",
    "        \n",
    "         \n",
    "        s_2.write(dict(x=x_2, y=y_2))\n",
    "        s_3.write(dict(x=x_3, y=y_3)) \n",
    "        \n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        s_1.write(dict(x=x_1, y=y_1))  \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    if only_new_predictions_flag == False:\n",
    "        \n",
    "        x_1 = target.iloc[:i].index\n",
    "        y_1 = target.iloc[:i]\n",
    "\n",
    "        x_2 = prediction_series.iloc[:i].index\n",
    "        y_2 = prediction_series.iloc[:i] \n",
    "\n",
    "    \n",
    "        x_3 = forecast_confint_df.High_ConfInterval_Boundary.iloc[:i].index\n",
    "        y_3 = forecast_confint_df.High_ConfInterval_Boundary.iloc[:i] \n",
    "    \n",
    "    #x_4 = forecast_confint_df.Low_ConfInterval_Boundary.iloc[:i].index\n",
    "    #y_4 = forecast_confint_df.Low_ConfInterval_Boundary.iloc[:i] \n",
    "    \n",
    "    # Send data to your plot\n",
    "     \n",
    " \n",
    "    #s_4.write(dict(x=x_4, y=y_4))  \n",
    " \n",
    "    #     Write numbers to stream to append current data on plot,\n",
    "    #     write lists to overwrite existing data on plot\n",
    "    \n",
    "       \n",
    "    \n",
    "    #x_1 = ts.iloc[:i+forecast_period].index\n",
    "    #y_1 = ts.iloc[:i+forecast_period]\n",
    "    #s_1.write(dict(x=x_1, y=y_1))  \n",
    "    \n",
    "        \n",
    "    #time.sleep(0.1)  # plot a point every second    \n",
    "    i += 1\n",
    "    \n",
    "   \n",
    "# Close the stream when done plotting\n",
    "s_1.close() \n",
    "s_2.close() \n",
    "s_3.close() \n",
    "#s_4.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "px_ser[prediction_series.index].plot()\n",
    "prediction_series.plot()\n",
    "prediction_series.rolling(2).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
