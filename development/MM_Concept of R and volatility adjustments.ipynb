{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('..')\n",
    "from backtester import matlab, backtester\n",
    "from backtester.analysis import *\n",
    "from backtester.strategy import StrategyBase, OptParam\n",
    "from backtester.swarms import SwarmManager, SwarmRanker\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility exploration of EXOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "exos_data = {}\n",
    "for fn in os.listdir('../mat/'):\n",
    "    if '.mat' not in fn:\n",
    "        continue\n",
    "        \n",
    "    d, info = matlab.loaddata('../mat/'+fn)\n",
    "    n = info['underlying']+\"_\"+info['name']\n",
    "    print(n)\n",
    "    print(fn)\n",
    "    print('----')\n",
    "    exos_data[n] = d.exo\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this figure we have a several different EXOs, with extremely different volatilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exo_df = pd.DataFrame(exos_data)\n",
    "exo_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive stats for every EXO returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exo_df.diff().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual comparison of volatility of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exo_df.diff().plot.box(sym='', rot=34);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The question: how could we equalize volatility of each EXO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking \"R concept\" with \"Volatility adjusted size\"\n",
    "* I chose median as volatility metric, because it less sensitive to short term volatility bursts than moving average.\n",
    "* We have only close prices of EXO, that why we are using |exo - exo[-1] | (absolute returns of EXO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 60 business days rolling window ~~ 1 quarter of time\n",
    "#\n",
    "volatility = exo_df.diff().abs().rolling(100).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(15,10)\n",
    "volatility.plot();\n",
    "title(\"Median volatility of EXOs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our goal is in implementing risk parity or equal risk across unequally volatile products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let we want to risk 1000 per single volatiliry unit at trade\n",
    "\n",
    "Then, our positon should be equal to: [AmmountInDollars] / [VolatilityUnit]\n",
    "\n",
    "Common sense of R is how many shares of each EXO index we should buy or sell to equalize dollar volatility of each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = 1000.0 / volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-adjusted returns of EXOs analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_adj_exo_df = exo_df.diff() * R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_adj_exo_df.cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_adj_exo_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exo_df.diff().plot.box(sym='', rot=34, title='EXO returns (USD) without adjustments');\n",
    "r_adj_exo_df.plot.box(sym='', rot=34, title='EXO returns (USD) with volatility adjustments');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitfalls of volatility adjustment method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing low volatility periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience, volatility adjustment method has one serious issue. When the volatility of an asset is abnormally low the position size is tending to be higher than usual. In that case we have a probability of substantial loss if volatility returns to normal or high values.\n",
    "\n",
    "We can manage this problem if we include lower bound constraints in volatility formula calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = exo_df.diff().abs()\n",
    "#\n",
    "# let our lower bound constraints is 100-period 30% percintile of vola\n",
    "#\n",
    "vol_contraints = v.rolling(200).quantile(0.4)\n",
    "\n",
    "volatility_with_constraints = volatility.apply( lambda x: np.maximum(x, vol_contraints[x.name] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volatility.EP_BearishCollarBrokenWing.plot()\n",
    "volatility_with_constraints.EP_BearishCollarBrokenWing.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressing results as R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact in the formula R = 1000.0 / volatility, R is not a result of its calculation, but 1000.0 USD value. Which means that we willing to risk about 1000.0 USD per volatility unit.\n",
    "\n",
    "Thats why we could express trading systems backtesting results as Rs factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strategyname = 'strategy_270225'\n",
    "d, info = matlab.loaddata('../mat/'+strategyname+'.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Position size\n",
    "# Volatility adjusted\n",
    "volatility = d.exo.diff().abs().rolling(60).median()\n",
    "R = 1000.0 \n",
    "size = R / volatility\n",
    "\n",
    "\n",
    "slow_ma = d.exo.rolling(5).mean()\n",
    "fast_ma = d.exo.rolling(6).mean()\n",
    "\n",
    "short_entry = CrossDown(fast_ma, slow_ma)\n",
    "short_exit = (CrossUp(fast_ma, slow_ma)) \n",
    "\n",
    "direction = -1\n",
    "pl, inposition = backtester.backtest(d, short_entry, short_exit, direction )\n",
    "equity, stats = backtester.stats(pl, inposition, positionsize=size)\n",
    "\n",
    "#X axis, initial equity curve\n",
    "#Colored blue\n",
    "x=equity\n",
    "x.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common USD stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our net profit is 134.1R and our MaxDrawDown is -44R, Average trade is 1.19R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.Series(stats) / R).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(equity / R).round(2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
